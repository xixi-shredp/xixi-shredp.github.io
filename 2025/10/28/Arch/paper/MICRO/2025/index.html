<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>MICRO 2025 论文简介 | xixi's blog</title><meta name="author" content="xixi"><meta name="copyright" content="xixi"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="MICRO 2025 论文简介">
<meta property="og:type" content="article">
<meta property="og:title" content="MICRO 2025 论文简介">
<meta property="og:url" content="https://xixi-shredp.github.io/2025/10/28/Arch/paper/MICRO/2025/index.html">
<meta property="og:site_name" content="xixi&#39;s blog">
<meta property="og:description" content="MICRO 2025 论文简介">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://xixi-shredp.github.io/img/avatar.jpg">
<meta property="article:published_time" content="2025-10-28T11:24:21.000Z">
<meta property="article:modified_time" content="2026-02-08T15:32:07.575Z">
<meta property="article:author" content="xixi">
<meta property="article:tag" content="CPU, Computer Architechture, OS">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://xixi-shredp.github.io/img/avatar.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "MICRO 2025 论文简介",
  "url": "https://xixi-shredp.github.io/2025/10/28/Arch/paper/MICRO/2025/",
  "image": "https://xixi-shredp.github.io/img/avatar.jpg",
  "datePublished": "2025-10-28T11:24:21.000Z",
  "dateModified": "2026-02-08T15:32:07.575Z",
  "author": [
    {
      "@type": "Person",
      "name": "xixi",
      "url": "https://xixi-shredp.github.io"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.svg"><link rel="canonical" href="https://xixi-shredp.github.io/2025/10/28/Arch/paper/MICRO/2025/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=5.5.4"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@7.1.0/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.13.0/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'MICRO 2025 论文简介',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 8.1.1"></head><body><div class="bg-animation" id="web_bg" style="background-image: url(/img/default_top.jpg);"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">47</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">29</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/img/default_top.jpg);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><img class="site-icon" src="/img/favicon.svg" alt="Logo"><span class="site-name">xixi's blog</span></a><a class="nav-page-title" href="/"><span class="site-name">MICRO 2025 论文简介</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  Back to Home</span></span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">MICRO 2025 论文简介</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2025-10-28T11:24:21.000Z" title="Created 2025-10-28 19:24:21">2025-10-28</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2026-02-08T15:32:07.575Z" title="Updated 2026-02-08 23:32:07">2026-02-08</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Arch/">Arch</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Arch/paper/">paper</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Arch/paper/MICRO/">MICRO</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h2 id="A-TRRIP-Down-Memory-Lane-Temperature-Based-Re-Reference-Interval-Prediction-For-Instruction-Caching"><a href="#A-TRRIP-Down-Memory-Lane-Temperature-Based-Re-Reference-Interval-Prediction-For-Instruction-Caching" class="headerlink" title="A TRRIP Down Memory Lane: Temperature-Based Re-Reference Interval Prediction For Instruction Caching"></a>A TRRIP Down Memory Lane: Temperature-Based Re-Reference Interval Prediction For Instruction Caching</h2><p>Author: Henry Kao(Huawei Technologies Canada), Nikhil Sreekumar(Huawei Technologies Canada), Prabhdeep Singh Soni(Huawei Technologies Canada), Ali Sedaghati(Huawei Technologies Canada), Fang Su(Huawei Technologies), Bryan Chan(Huawei Technologies Canada)</p>
<p>Abstruct:<br>现代移动端 CPU 的软件由于其复杂的运行时行为导致相同指令在执行之间的 reuse distance 较高，对传统的指令缓存替换策略构成了挑战。移动端代码通常会在 CPU 前端产生大量的停顿，从而导致 CPU 其他资源的 starvation 。这些应用程序及其代码规模预计会以比可用片上内存更快的速度增长，这是由于功耗和面积限制所致，使得传统的以硬件为中心的指令缓存管理方法变得不足。我们提出了一种名为 TRRIP（基于温度的 Re-Reference Interval Prediction）的新型软硬件协同设计方法，该方法使编译器能够根据“温度”（hot&#x2F;cold）对代码进行分析、分类和转换，并通过基于代码页面属性的定义良好的操作系统接口向硬件提供代码温度信息的汇总。TRRIP 的轻量级硬件扩展利用代码温度属性优化指令缓存替换策略，从而降低热代码的踢出率。TRRIP 被设计为适用于具有严格软硬件组件功能要求的真实移动系统，能够在已使用 PGO 优化移动代码的 RRIP 缓存替换基础上，将指令的 L2 MPKI 降低 26.5% ，从而实现几何平均 3.9% 的速度提升。</p>
<h2 id="ATR-Out-of-Order-Register-Release-Exploiting-Atomic-Regions"><a href="#ATR-Out-of-Order-Register-Release-Exploiting-Atomic-Regions" class="headerlink" title="ATR: Out-of-Order Register Release Exploiting Atomic Regions"></a>ATR: Out-of-Order Register Release Exploiting Atomic Regions</h2><p>Author: Yinyuan Zhao(University of California, Santa Cruz), Surim Oh(University of California, Santa Cruz), Mingsheng Xu(University of California, Santa Cruz), Heiner Litz(University of California, Santa Cruz)</p>
<p>Abstruct:<br>现代超标量处理器需要大型物理寄存器文件以支持大量在途指令，这对于实现更高的 ILP （指令级并行性）和 IPC （每时钟周期指令数）至关重要。传统的寄存器重命名技术会保守地释放物理寄存器，直到重新定义同一架构寄存器的指令提交，这会导致寄存器利用率不高。特别是，寄存器经常被分配很多个周期，尽管它们已不再被使用。为解决这一不足，先前的方法探索了早期寄存器释放，其目标是尽可能早地释放已完全使用的寄存器。然而，这些技术要么不安全，要么过于保守，限制了其优势。<br>我们观察到，在 SPEC2017int 中，超过 17% 的已分配寄存器位于原子提交区域，即不包含条件分支或引发异常的指令的序列。此类区域内的指令保证会原子性地提交或刷新，从而允许安全地提前释放由区域第一条指令分配的寄存器。特别是，**可以在不需要等待重新定义架构寄存器的指令提交的情况下释放寄存器。我们提出了一种新颖的重命名技术，利用这一洞察来减少寄存器文件的压力。该技术通过一种简单的机制识别原子提交区域，无需使用栈、队列、额外内存或 shadow cells。**我们证明，对于 SPEC2017int 基准测试，所提出的寄存器重命名方案在 64-entry 寄存器文件中实现了平均 5.13% 的加速，在 224-entry 寄存器文件中实现了平均 1.48% 的加速。</p>
<h2 id="Beyond-Page-Migration-Enhancing-Tiered-Memory-Performance-via-Integrated-Last-Level-Cache-Management-and-Page-Migration"><a href="#Beyond-Page-Migration-Enhancing-Tiered-Memory-Performance-via-Integrated-Last-Level-Cache-Management-and-Page-Migration" class="headerlink" title="Beyond Page Migration: Enhancing Tiered Memory Performance via Integrated Last-Level Cache Management and Page Migration"></a>Beyond Page Migration: Enhancing Tiered Memory Performance via Integrated Last-Level Cache Management and Page Migration</h2><p>Author: Hwanjun Lee(DGIST), Minho Kim(DGIST), Yeji Jung(DGIST), Seonmu Oh(DGIST), Ki-Dong Kang(ETRI), Seunghak Lee(Samsung Electronics), Daehoon Kim(Yonsei University)</p>
<p>Abstruct:<br>新兴的内存互连技术，如 Compute Express Link（CXL），通过集成异构内存组件（如本地 DRAM 和 CXL 附加的 DRAM）实现了可扩展的内存扩展。这些分层内存系统在带宽和容量方面具有潜在优势，但其异构性能特性对高效的内存管理提出了重大挑战。传统方法，包括基于 hotness 的页面放置，通过将频繁访问的数据保留在近端内存中以优先降低延迟。然而，这些方法通常无法有效利用总内存带宽，导致在内存密集型工作负载下出现流量不平衡和性能下降。此外，对昂贵的页面迁移的依赖引入了阻碍应对工作负载变化的开销。为解决这些问题，我们提出了 **TierTune ，这是一种集成 LLC Partitioning 和 page migration 的动态内存管理框架。TierTune 在近端和远端内存节点之间动态划分 LLC，迅速缓解延迟不平衡，并比基于软件的页面迁移更有效地平衡内存流量。**我们进一步通过一种动态重新分配页面的迁移策略扩展了该方法，以解决持续的不平衡问题，在放置决策中结合缓存层次效应和带宽压力。实验评估表明，与最先进的页面迁移策略相比，TierTune 在多种工作负载下平均提升了 19.6% 的性能，这是通过更有效地平衡内存流量并减少迁移开销实现的。</p>
<h2 id="Drishti-Do-Not-Forget-Slicing-While-Designing-Last-Level-Cache-Replacement-Policies-for-Many-Core-Systems"><a href="#Drishti-Do-Not-Forget-Slicing-While-Designing-Last-Level-Cache-Replacement-Policies-for-Many-Core-Systems" class="headerlink" title="Drishti: Do Not Forget Slicing While Designing Last-Level Cache Replacement Policies for Many-Core Systems"></a>Drishti: Do Not Forget Slicing While Designing Last-Level Cache Replacement Policies for Many-Core Systems</h2><p>Author: Sweta(Indian Institute of Technology), Prerna Priyadarshini(Indian Institute of Technology), Biswabandan Panda(Indian Institute of Technology)</p>
<p>Abstruct:<br>高性能的 LLC 替换策略通过智能地决定哪些缓存行应保留在LLC中，从而缓解片外内存访问延迟。最先进的替换策略显著优于如LRU等传统策略。然而，这些策略在具有 sliced LLC 的多核系统上的有效性尚未得到评估，而这种结构在商用多核系统中很常见。最近的先进LLC替换策略采用了两个基本思想：(i) sampled cache; (ii) reuse predictor 。在单一的LLC中，存在一个 sampled cache 和一个 reuse predictor 。然而，在 sliced LLC 中，这些结构必须为每个 slice 单独创建。我们研究了 sliced LLC 与先进替换策略之间的相互作用，发现了几个未被探索的交互问题。每个 slice 的 reuse predictor 基于对特定 slice 的访问做出短视的决策，而不了解全局的 reuse 行为。解决这一问题的一个简单方法是设计一个由所有 LLC slices 共享的集中式 reuse predictor。然而，这将显著增加互连流量，需要更多的带宽来访问集中式 reuse predictor 。接下来，我们观察到，在 sliced LLC 中，用于 sampled cache 的 LLC sets 没有获得足够的 LLC misses 。由于这些 LLC sets 驱动 LLC 替换策略的决策，部分决策变得次优。<br>我们提出了 <strong>Drishti，旨在进一步提高 LLC 替换策略的有效性。我们提出两项改进：(i) 一个基于每个核心但全局的 reuse predictor ，结合局部（每个 slice）的 sampled cache，并认为无需全局 sampled cache；(ii) 每个 slice 的 dynamic sampled cache ，以提高用于 sampled cache 的 LLC sets 的利用率。</strong> 我们在具有 8MB、32MB 和 64MB sliced LLC 的四核、十六核和三十二核系统上评估了两种最先进的 LLC 替换策略—— Hawkeye 和 Mockingjay。在三十二核系统中，与基线 LRU 策略相比，Drishti 分别使 Hawkeye 和 Mockingjay 的性能提升了 5.6% 和 13.2% 。在没有 Drishti 的情况下，Hawkeye 和 Mockingjay 分别仅提升了 3.3% 和 6.7%。</p>
<h2 id="Learning-to-Walk-Architecting-Learned-Virtual-Memory-Translation"><a href="#Learning-to-Walk-Architecting-Learned-Virtual-Memory-Translation" class="headerlink" title="Learning to Walk: Architecting Learned Virtual Memory Translation"></a>Learning to Walk: Architecting Learned Virtual Memory Translation</h2><p>Author: Kaiyang Zhao(Carnegie Mellon University), Yuang Chen(Carnegie Mellon University), Xenia Xu(Carnegie Mellon University), Dan Schatzberg(Meta), Nastaran Hajinaza(Intel), Rupin Vakharwala(Intel), Andy Anderson(Intel), Dimitrios Skarlatos(Carnegie Mellon University)</p>
<p>Abstruct:<br>随着新兴数据中心应用对内存需求的增加，虚拟内存翻译再次受到关注，暴露出其作为显著性能瓶颈的问题。为了解决这一问题，本文介绍了学习型虚拟内存（LVM），这是一种能够有效提供最优单次访问地址翻译的页表结构。LVM 基于一种新颖的学习索引模型，该模型根据应用程序虚拟地址空间的特性动态适应地址翻译过程。此外，LVM 的学习索引占用极小的内存空间，不需要严格的物理连续性要求，在 MMU 中具有较高的缓存性，能够高效支持插入操作，并依赖简单的定点运算。最后，LVM 支持虚拟内存的所有功能，包括多种页面大小。我们通过在 Linux 中的一组操作系统（OS）扩展、RTL 综合以及跨广泛工作负载的全系统仿真对 LVM 进行了评估。LVM 平均将地址翻译开销降低了 44% ，同时将所需的页表遍历缓存面积减少了 1.5 倍。总体而言，LVM 在应用执行时间上实现了 2% 至 27% 的速度提升，并接近理想页表的性能（误差在 1% 以内）。</p>
<h2 id="LoopFrog-In-Core-Hint-Based-Loop-Parallelization"><a href="#LoopFrog-In-Core-Hint-Based-Loop-Parallelization" class="headerlink" title="LoopFrog: In-Core Hint-Based Loop Parallelization"></a>LoopFrog: In-Core Hint-Based Loop Parallelization</h2><p>Author: Marton Erdos(University of Cambridge), Utpal Bora(University of Cambridge), Akshay Bhosale(University of Cambridge), Bob Lytton(Arm), Ali M. Zaidi(Arm), Alexandra W. Chadwick(University of Cambridge), Yuxin Guo(University of Cambridge), Giacomo Gabrielli(Arm), Timothy M. Jones(University of Cambridge)</p>
<p>Abstruct:  为了扩展 ILP ，设计者构建了更深更宽的乱序超标量 CPU 。然而，这种方法随着每一代的发展会带来二次方增长的复杂度、面积和能耗成本。<strong>尽管小循环可能从更大的指令窗口中受益，而大循环可能通过跨核心的线程级并行性获得加速，但仍然存在未被利用的中间粒度并行性。</strong><br>我们提出 **LoopFrog ，以挖掘这一潜力，将线程级推测方案带入现代架构。LoopFrog 在微架构中通过单一线程并行执行多个循环迭代。**核心可根据编译器插入的提示生成未来循环迭代作为新的微架构线程片段，从而超越父线程的指令窗口，暴露一种与传统 ILP 和 TLP 正交的新型中粒度并行性。LoopFrog 监控执行线程片段之间的数据依赖关系，对真依赖关系进行数据转发，并在顺序违规时回滚推测性线程片段。<br>使用基于 LLVM 的编译器插入提示，我们实现了循环速度的几何平均提升 43% ，在 SPEC CPU 2006 和 SPEC CPU 2017 基准测试中，分别实现了 9.2% 和 9.5% 的整体程序加速，且仅带来适度的面积和功耗开销。</p>
<h2 id="Multi-Stream-Squash-Reuse-for-Control-Independent-Processors"><a href="#Multi-Stream-Squash-Reuse-for-Control-Independent-Processors" class="headerlink" title="Multi-Stream Squash Reuse for Control-Independent Processors"></a>Multi-Stream Squash Reuse for Control-Independent Processors</h2><p>Author: Qingxuan Kang(National University of Singapore), Trevor E. Carlson(National University of Singapore)</p>
<p>Abstruct:<br>根据 Amdahl’s Law ，单核性能对于缓解应用程序中的串行瓶颈仍然至关重要。然而，难以预测的分支会给实现高指令级并行性（ILP）带来重大挑战，这是由于频繁的流水线清空所致。在典型的处理器中，当分支被错误预测时，后续指令会被无差别地清空，包括那些在未来一定会被执行的潜在有用指令，这些指令被称为控制无关（CI）指令。尽管现有的 CI 方案在利用典型的控制流结构方面是有效的，但这些技术忽略了更一般的收敛场景。我们的分析表明，<strong>由于程序的动态执行行为，重定向的指令流不仅可以与最后被清空的流重新汇聚，还可以与多个先前的流重新汇聚。如果仅考虑最后被清空的指令流与当前流之间的交互，平均有 10% （最高达 31% ）的收敛机会会被忽略。</strong><br>本文中，我们介绍了 <strong>Multi-Stream Squash Reuse ，该技术从多个先前 squashed 的执行流中发现执行 reuse 机会。我们使用带标签的重命名映射，以实现任意两个程序执行状态之间的两两比较，从而识别数据重用</strong>。我们的方案在 IPC 方面实现了平均提升，分别为 2.2% (SPECint2006), 0.8%(SPECint2017) 和 2.4% (GAP)，并在 SPECint2006 和 GAP 基准测试套件中分别达到了最高提升 8.9%(astar), 6.1%(bc) 和 4.0%(cc)</p>
<h2 id="SHADOW-Simultaneous-Multi-Threading-Architecture-with-Asymmetric-Threads"><a href="#SHADOW-Simultaneous-Multi-Threading-Architecture-with-Asymmetric-Threads" class="headerlink" title="SHADOW: Simultaneous Multi-Threading Architecture with Asymmetric Threads"></a>SHADOW: Simultaneous Multi-Threading Architecture with Asymmetric Threads</h2><p>Author: Ishita Chaturvedi(Princeton University), Bhargav Reddy Godala(AheadComputing), Abiram Gangavaram(Princeton University), Daniel Flyer(Princeton University), Tyler Sorensen(Microsoft), Tor M. Aamodt(University of British Columbia), David I. August(Princeton University)</p>
<p>Abstruct:<br>许多重要的应用由于不规则的稀疏性和不可预测的内存访问模式，表现出在指令级并行性（ILP）和线程级并行性（TLP）之间的需求变化。传统 CPU 专注于其中一种但无法平衡两者，导致执行资源未被充分利用并出现性能瓶颈。解决这一挑战需要一种能够无缝且高效适应工作负载变化的架构。<br>本文介绍了 **SHADOW ，这是首个非对称 SMT 核心，它通过在同一核心上同时执行乱序（OoO）和顺序（InO）线程，动态地平衡 ILP 和 TLP。SHADOW 通过利用 OoO 线程中的深层 ILP 和轻量级 InO 线程中的高 TLP 来最大化 CPU 利用率。**它支持运行时配置，使应用程序能够优化 OoO 与 InO 执行的混合比例。在九个不同的基准测试中评估，SHADOW 相对于一个 OoO CPU 实现了最高 <strong>3.16 倍</strong>的加速和平均 1.33 倍的提升，仅带来 1% 的面积和功耗开销。通过动态适应工作负载特性，SHADOW 优于传统架构，在不牺牲计算密集型性能的前提下，有效加速内存受限的工作负载。</p>
<h2 id="Symbiotic-Task-Scheduling-and-Data-Prefetching"><a href="#Symbiotic-Task-Scheduling-and-Data-Prefetching" class="headerlink" title="Symbiotic Task Scheduling and Data Prefetching"></a>Symbiotic Task Scheduling and Data Prefetching</h2><p>Author: Gilead Posluns(University of Toronto), Mark C. Jeffrey(University of Toronto)</p>
<p>Abstruct:<br>任务并行编程模型使程序员能够从不规则的应用程序中提取并行性。由于基于软件的任务并行运行时会对细粒度任务造成严重的开销，架构师设计了具有硬件任务管理支持的多核处理器。这些硬件任务并行系统可以将具有挑战性的负载扩展到数百个核心，但由于任务时间较短（100周期），无法使用传统的预取器。缺乏预取功能，它们常常将 DRAM 延迟暴露给应用程序，从而抵消了硬件的性能优势。我们提出了**任务种子预取器（TSP）和内存响应任务调度器（MRS），这是一个协同工作的组合，能够在通用任务并行硬件中提升性能。TSP 通过任务描述符学习并预取每个任务函数的数据访问模式，该描述符由任务调度器排队。MRS 通过利用来自 TSP 的预取状态来优化核心利用率，从而增强基线任务到核心的调度策略。**TSP 和 MRS 共同在 256 核任务并行系统上为 13 个基准测试提供了最高 3.1 倍（gmeans最高1.4倍）的加速效果，这些系统本身比并行软件快 3 至 60 倍。</p>
<h2 id="Titan-I-An-Open-Source-High-Performance-RISC-V-Vector-Core"><a href="#Titan-I-An-Open-Source-High-Performance-RISC-V-Vector-Core" class="headerlink" title="Titan-I: An Open-Source, High Performance RISC-V Vector Core"></a>Titan-I: An Open-Source, High Performance RISC-V Vector Core</h2><p>Author: Jiuyang Liu(Huazhong University of Science and Technology), Qinjun Li(Institute of Software Chinese Academy of Sciences), Yunqian Luo(Tsinghua University), Hongbin Zhang(Institute of Software Chinese Academy of Sciences), Jiongjia Lu(Xinpian Technology Co., Ltd.), Shupei Fan(Tsinghua University), Jianhao Ye(University of Chinese Academy of Sciences), Yang Liu(Institute of Software Chinese Academy of Sciences), Xiaoyi Liu(Tsinghua University), Yanqi Yang(Huazhong University of Science and Technology), Zewen Ye(Zhejiang University), Yuhang Zeng(Xinpian Technology Co., Ltd.), Ao Shen(Tsinghua University), Rui Huang(Xinpian Technology Co., Ltd.), Wei Cong(UCUN Technology Inc), Xuecheng Zou(Henan Academy of Sciences), and Mingyu Gao(Tsinghua University).</p>
<p>Abstruct:<br>向量处理已从早期的系统如 CDC STAR-100 和 Cray-1 发展到现代的指令集架构（ISA），如 ARM 的可扩展向量扩展（SVE）和 RISC-V 向量（RVV）扩展。然而，由于传统架构中的开销，对现代工作负载进行向量处理的扩展面临挑战。我们介绍了 Titan-I(T1) 一个乱序 RVV 架构，用于扩展 ILP 和 DLP。TI 集成了一个粗粒度布局求解器、一个数据通路范围的排列单元以及用于掩码寄存器的寄存器缓存，从而提高了带宽并降低了延迟。它还使用了多种乱序（OoO）技术，如细粒度链式处理、指令发布-提交和内存交错，以优化更宽向量数据通路的指令级并行性（ILP）。T1 在密码学应用中性能优于通用图形处理器（GP-GPU）和其他向量核心，在仅占用 GA102（Nvidia 3090）的 40% 流式多处理器（SM）面积的情况下，相较于 GB202（Nvidia 5090）实现了最高 1.85 倍的加速，相较于 GA102 实现了最高 2.41 倍的加速。在高性能计算（HPC）工作负载中，T1 在仅占用 HiSilicon TaiShan V120（KP920）19% 面积的情况下表现出兼容的性能，当将 T1 的数据通路扩展 4 倍时，其性能相比该芯片提升了4.59 倍。此外，T1 对内存延迟表现出强大的容忍能力，在纯 DDR 模式下，其性能比 SpacemiT X60（K1）提升了 8.05 倍。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="https://xixi-shredp.github.io">xixi</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://xixi-shredp.github.io/2025/10/28/Arch/paper/MICRO/2025/">https://xixi-shredp.github.io/2025/10/28/Arch/paper/MICRO/2025/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-share"><div class="social-share" data-image="/img/avatar.jpg" data-sites="facebook,x,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/10/29/Arch/ooo/issue/issue/" title="OOO CPU Issue Stage"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">Previous</div><div class="info-item-2">OOO CPU Issue Stage</div></div><div class="info-2"><div class="info-item-1"> InOrder Issue Logic 指令需要等待所有先前的指令都发射后才可以发射 实现简单：仅需要 scoreboarding a data dependence table: 每个 entry 代表一个寄存器是否 available a resource table: 追踪所有功能单元的状态   特殊的顺序处理器： VLIW processors   Out-Of-Order Issue Logic 往往是处理器流水线的关键路径    发射阶段 (Issue Stage) 的任务：接收来自重命名之后的指令（顺序），乱序地送到功能单元去执行 主要电路：  发射队列 (Issue Queue) &#x2F; 保留站 (Reservation Station) 分配 (Allocation) 电路 选择 (Select) 电路 &#x2F; 仲裁 (Arbiter) 电路 唤醒 (Wake-up) 电路  流水线发射队列中的指令被仲裁电路选中执行的条件：  源操作数均已准备好 仲裁电路允许发射 可以从寄存器堆 &#x2F; payload RAM &#x2F; 旁路网络中获得源...</div></div></div></a><a class="pagination-related" href="/2025/10/28/os/generic/structure/" title="操作系统结构"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">Next</div><div class="info-item-2">操作系统结构</div></div><div class="info-2"><div class="info-item-1"> 参考: 中国科学院大学 2025年秋《高级操作系统教程》课件   重要设计原则：策略与机制的分离  策略（Policy）：要做什么 – 相对动态 机制（Mechanism）：该怎么做 – 相对静态 操作系统可仅通过调整策略来适应不同应用的需求  操作系统架构分类：  Monolithic-Kernel, 宏内核 Microkernel, 微内核 Exokernel, 外核 Multikernel, 多内核  操作系统结构的演进与生态:  系统软件需要一条演进之路 尽可能集成现有的POSIX API&#x2F;Linux ABI 避免棘手的系统调用（如fork） 避免不可扩展的POSIX API   系统软件一直在不断演化 例：Linux Userspace I&#x2F;O (UIO)，向微内核近了一步 单节点下也存在更多的分布式、低时延的可编程设备 非易失性内存的出现可能推动存储层次在OS中的完全改革    Monolithic-Kernel, 宏内核  整个系统分为内核与应用两层  内核：运行在特权级，集中控制所有计算资源 应用：运行在非特权级，受内核管理，使用内核服务  ...</div></div></div></a></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">xixi</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">47</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">29</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xixi-shredp"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/xixi-shredp" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">This is my blog, for learning and communication purposes only. If there is any copyright infringement, please leave a message via email on GitHub.</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#A-TRRIP-Down-Memory-Lane-Temperature-Based-Re-Reference-Interval-Prediction-For-Instruction-Caching"><span class="toc-number">1.</span> <span class="toc-text">A TRRIP Down Memory Lane: Temperature-Based Re-Reference Interval Prediction For Instruction Caching</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ATR-Out-of-Order-Register-Release-Exploiting-Atomic-Regions"><span class="toc-number">2.</span> <span class="toc-text">ATR: Out-of-Order Register Release Exploiting Atomic Regions</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Beyond-Page-Migration-Enhancing-Tiered-Memory-Performance-via-Integrated-Last-Level-Cache-Management-and-Page-Migration"><span class="toc-number">3.</span> <span class="toc-text">Beyond Page Migration: Enhancing Tiered Memory Performance via Integrated Last-Level Cache Management and Page Migration</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Drishti-Do-Not-Forget-Slicing-While-Designing-Last-Level-Cache-Replacement-Policies-for-Many-Core-Systems"><span class="toc-number">4.</span> <span class="toc-text">Drishti: Do Not Forget Slicing While Designing Last-Level Cache Replacement Policies for Many-Core Systems</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Learning-to-Walk-Architecting-Learned-Virtual-Memory-Translation"><span class="toc-number">5.</span> <span class="toc-text">Learning to Walk: Architecting Learned Virtual Memory Translation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#LoopFrog-In-Core-Hint-Based-Loop-Parallelization"><span class="toc-number">6.</span> <span class="toc-text">LoopFrog: In-Core Hint-Based Loop Parallelization</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Multi-Stream-Squash-Reuse-for-Control-Independent-Processors"><span class="toc-number">7.</span> <span class="toc-text">Multi-Stream Squash Reuse for Control-Independent Processors</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SHADOW-Simultaneous-Multi-Threading-Architecture-with-Asymmetric-Threads"><span class="toc-number">8.</span> <span class="toc-text">SHADOW: Simultaneous Multi-Threading Architecture with Asymmetric Threads</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Symbiotic-Task-Scheduling-and-Data-Prefetching"><span class="toc-number">9.</span> <span class="toc-text">Symbiotic Task Scheduling and Data Prefetching</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Titan-I-An-Open-Source-High-Performance-RISC-V-Vector-Core"><span class="toc-number">10.</span> <span class="toc-text">Titan-I: An Open-Source, High Performance RISC-V Vector Core</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/11/06/os/generic/mm/" title="OS Virtual Memory Management">OS Virtual Memory Management</a><time datetime="2025-11-06T06:03:30.000Z" title="Created 2025-11-06 14:03:30">2025-11-06</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/11/06/os/linux/riscv/boot/" title="Linux RISC-V Boot 流程">Linux RISC-V Boot 流程</a><time datetime="2025-11-06T01:44:36.000Z" title="Created 2025-11-06 09:44:36">2025-11-06</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/11/04/os/linux/boot/" title="Linux Boot 过程">Linux Boot 过程</a><time datetime="2025-11-04T06:09:06.000Z" title="Created 2025-11-04 14:09:06">2025-11-04</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/11/04/os/generic/boot/init/" title="操作系统初始化">操作系统初始化</a><time datetime="2025-11-03T16:16:20.000Z" title="Created 2025-11-04 00:16:20">2025-11-04</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/11/03/os/generic/trap/" title="操作系统：Interupt, Exception, Syscall">操作系统：Interupt, Exception, Syscall</a><time datetime="2025-11-03T15:01:01.000Z" title="Created 2025-11-03 23:01:01">2025-11-03</time></div></div></div></div></div></div></main><footer id="footer" style="background: linear-gradient(160deg, #4D063C, #3E064D, #23064D, #08064D);"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2025 - 2026 By xixi</span><span class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></span></div><div class="footer_custom_text">Life is so Beautify!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=5.5.4"></script><script src="/js/main.js?v=5.5.4"></script><div class="js-pjax"><script>(() => {
  const parseViewBox = viewBox => {
    if (!viewBox) return null
    const parts = viewBox.trim().split(/[\s,]+/).map(n => Number(n))
    if (parts.length !== 4 || parts.some(n => Number.isNaN(n))) return null
    return parts
  }

  const getSvgViewBox = svg => {
    const attr = parseViewBox(svg.getAttribute('viewBox'))
    if (attr) return attr

    // Fallback: use bbox to build a viewBox
    try {
      const bbox = svg.getBBox()
      if (bbox && bbox.width && bbox.height) return [bbox.x, bbox.y, bbox.width, bbox.height]
    } catch (e) {
      // getBBox may fail on some edge cases; ignore
    }

    const w = Number(svg.getAttribute('width')) || 0
    const h = Number(svg.getAttribute('height')) || 0
    if (w > 0 && h > 0) return [0, 0, w, h]
    return [0, 0, 100, 100]
  }

  const setSvgViewBox = (svg, vb) => {
    svg.setAttribute('viewBox', `${vb[0]} ${vb[1]} ${vb[2]} ${vb[3]}`)
  }

  const clamp = (v, min, max) => Math.max(min, Math.min(max, v))

  const openSvgInNewTab = ({ source, initViewBox }) => {
    const getClonedSvg = () => {
      if (typeof source === 'string') {
        const template = document.createElement('template')
        template.innerHTML = source.trim()
        const svg = template.content.querySelector('svg')
        return svg ? svg.cloneNode(true) : null
      }
      if (source && typeof source.cloneNode === 'function') {
        return source.cloneNode(true)
      }
      return null
    }

    const clone = getClonedSvg()
    if (!clone) return
    if (initViewBox && initViewBox.length === 4) {
      clone.setAttribute('viewBox', initViewBox.join(' '))
    }
    if (!clone.getAttribute('xmlns')) clone.setAttribute('xmlns', 'http://www.w3.org/2000/svg')
    if (!clone.getAttribute('xmlns:xlink') && clone.outerHTML.includes('xlink:')) {
      clone.setAttribute('xmlns:xlink', 'http://www.w3.org/1999/xlink')
    }
    // inject background to match current theme
    const isDark = document.documentElement.getAttribute('data-theme') === 'dark'
    const bg = getComputedStyle(document.body).backgroundColor || (isDark ? '#1e1e1e' : '#ffffff')
    if (!clone.style.background) clone.style.background = bg

    const serializer = new XMLSerializer()
    const svgSource = serializer.serializeToString(clone)
    const htmlSource = `<!doctype html><html><head><meta charset="utf-8" />
      <style>
        html, body { width: 100%; height: 100%; margin: 0; display: flex; align-items: center; justify-content: center; background: ${bg}; }
        svg { max-width: 100%; max-height: 100%; height: auto; width: auto; }
      </style>
      </head><body>${svgSource}</body></html>`
    const blob = new Blob([htmlSource], { type: 'text/html;charset=utf-8' })
    const url = URL.createObjectURL(blob)
    window.open(url, '_blank', 'noopener')
    setTimeout(() => URL.revokeObjectURL(url), 30000)
  }

  const attachMermaidViewerButton = wrap => {
    let btn = wrap.querySelector('.mermaid-open-btn')
    if (!btn) {
      btn = document.createElement('button')
      btn.type = 'button'
      btn.className = 'mermaid-open-btn'
      wrap.appendChild(btn)
    }

    btn.innerHTML = '<i class="fa fa-search fa-fw" aria-hidden="true"></i>'

    if (!btn.__mermaidViewerBound) {
      btn.addEventListener('click', e => {
        e.preventDefault()
        e.stopPropagation()
        const svg = wrap.__mermaidOriginalSvg || wrap.querySelector('svg')
        if (!svg) return
        const initViewBox = wrap.__mermaidInitViewBox
        if (typeof svg === 'string') {
          openSvgInNewTab({ source: svg, initViewBox })
          return
        }
        openSvgInNewTab({ source: svg, initViewBox })
      })
      btn.__mermaidViewerBound = true
    }
  }

  // Zoom around a point (px, py) in the SVG viewport (in viewBox coordinates)
  const zoomAtPoint = (vb, factor, px, py) => {
    const w = vb[2] * factor
    const h = vb[3] * factor
    const nx = px - (px - vb[0]) * factor
    const ny = py - (py - vb[1]) * factor
    return [nx, ny, w, h]
  }

  const initMermaidGestures = wrap => {
    const svg = wrap.querySelector('svg')
    if (!svg) return

    // Ensure viewBox exists so gestures always work
    const initVb = getSvgViewBox(svg)
    wrap.__mermaidInitViewBox = initVb
    wrap.__mermaidCurViewBox = initVb.slice()
    setSvgViewBox(svg, initVb)

    // Avoid binding multiple times on themeChange/pjax
    if (wrap.__mermaidGestureBound) return
    wrap.__mermaidGestureBound = true

    // Helper: map client (viewport) coordinate -> viewBox coordinate
    const clientToViewBox = (clientX, clientY) => {
      const rect = svg.getBoundingClientRect()
      const vb = wrap.__mermaidCurViewBox || getSvgViewBox(svg)
      const x = vb[0] + (clientX - rect.left) * (vb[2] / rect.width)
      const y = vb[1] + (clientY - rect.top) * (vb[3] / rect.height)
      return { x, y, rect, vb }
    }

    const state = {
      pointers: new Map(),
      startVb: null,
      startDist: 0,
      startCenter: null
    }

    const clampVb = vb => {
      const init = wrap.__mermaidInitViewBox || vb
      const minW = init[2] * 0.1
      const maxW = init[2] * 10
      const minH = init[3] * 0.1
      const maxH = init[3] * 10
      vb[2] = clamp(vb[2], minW, maxW)
      vb[3] = clamp(vb[3], minH, maxH)
      return vb
    }

    const setCurVb = vb => {
      vb = clampVb(vb)
      wrap.__mermaidCurViewBox = vb
      setSvgViewBox(svg, vb)
    }

    const onPointerDown = e => {
      // Allow only primary button for mouse
      if (e.pointerType === 'mouse' && e.button !== 0) return
      svg.setPointerCapture(e.pointerId)
      state.pointers.set(e.pointerId, { x: e.clientX, y: e.clientY })

      if (state.pointers.size === 1) {
        state.startVb = (wrap.__mermaidCurViewBox || getSvgViewBox(svg)).slice()
      } else if (state.pointers.size === 2) {
        const pts = [...state.pointers.values()]
        const dx = pts[0].x - pts[1].x
        const dy = pts[0].y - pts[1].y
        state.startDist = Math.hypot(dx, dy)
        state.startVb = (wrap.__mermaidCurViewBox || getSvgViewBox(svg)).slice()
        state.startCenter = { x: (pts[0].x + pts[1].x) / 2, y: (pts[0].y + pts[1].y) / 2 }
      }
    }

    const onPointerMove = e => {
      if (!state.pointers.has(e.pointerId)) return
      state.pointers.set(e.pointerId, { x: e.clientX, y: e.clientY })

      // Pan with 1 pointer
      if (state.pointers.size === 1 && state.startVb) {
        const p = [...state.pointers.values()][0]
        const prev = { x: e.clientX - e.movementX, y: e.clientY - e.movementY }
        // movementX/Y unreliable on touch, compute from stored last position
        const last = wrap.__mermaidLastSinglePointer || p
        const dxClient = p.x - last.x
        const dyClient = p.y - last.y
        wrap.__mermaidLastSinglePointer = p

        const { rect } = clientToViewBox(p.x, p.y)
        const vb = (wrap.__mermaidCurViewBox || getSvgViewBox(svg)).slice()
        const dx = dxClient * (vb[2] / rect.width)
        const dy = dyClient * (vb[3] / rect.height)
        setCurVb([vb[0] - dx, vb[1] - dy, vb[2], vb[3]])
        return
      }

      // Pinch zoom with 2 pointers
      if (state.pointers.size === 2 && state.startVb && state.startDist > 0) {
        const pts = [...state.pointers.values()]
        const dx = pts[0].x - pts[1].x
        const dy = pts[0].y - pts[1].y
        const dist = Math.hypot(dx, dy)
        if (!dist) return
        const factor = state.startDist / dist // dist bigger => zoom in (viewBox smaller)

        const cx = (pts[0].x + pts[1].x) / 2
        const cy = (pts[0].y + pts[1].y) / 2
        const centerClient = { x: cx, y: cy }

        const pxy = clientToViewBox(centerClient.x, centerClient.y)
        const cpx = pxy.x
        const cpy = pxy.y

        const vb = zoomAtPoint(state.startVb, factor, cpx, cpy)
        setCurVb(vb)
      }
    }

    const onPointerUpOrCancel = e => {
      state.pointers.delete(e.pointerId)
      if (state.pointers.size === 0) {
        state.startVb = null
        state.startDist = 0
        state.startCenter = null
        wrap.__mermaidLastSinglePointer = null
      } else if (state.pointers.size === 1) {
        // reset single pointer baseline to avoid jump
        wrap.__mermaidLastSinglePointer = [...state.pointers.values()][0]
      }
    }

    // Wheel zoom (mouse/trackpad)
    const onWheel = e => {
      // ctrlKey on mac trackpad pinch; we treat both as zoom
      e.preventDefault()
      const delta = e.deltaY
      const zoomFactor = delta > 0 ? 1.1 : 0.9
      const { x, y } = clientToViewBox(e.clientX, e.clientY)
      const vb = (wrap.__mermaidCurViewBox || getSvgViewBox(svg)).slice()
      setCurVb(zoomAtPoint(vb, zoomFactor, x, y))
    }

    const onDblClick = () => {
      const init = wrap.__mermaidInitViewBox
      if (!init) return
      wrap.__mermaidCurViewBox = init.slice()
      setSvgViewBox(svg, init)
    }

    svg.addEventListener('pointerdown', onPointerDown)
    svg.addEventListener('pointermove', onPointerMove)
    svg.addEventListener('pointerup', onPointerUpOrCancel)
    svg.addEventListener('pointercancel', onPointerUpOrCancel)
    svg.addEventListener('wheel', onWheel, { passive: false })
    svg.addEventListener('dblclick', onDblClick)
  }

  const runMermaid = ele => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    ele.forEach((item, index) => {
      const mermaidSrc = item.firstElementChild

      // Clear old render (themeChange/pjax will rerun)
      const oldSvg = item.querySelector('svg')
      if (oldSvg) oldSvg.remove()
      item.__mermaidGestureBound = false

      const config = mermaidSrc.dataset.config ? JSON.parse(mermaidSrc.dataset.config) : {}
      if (!config.theme) {
        config.theme = theme
      }
      const mermaidThemeConfig = `%%{init: ${JSON.stringify(config)}}%%\n`
      const mermaidID = `mermaid-${index}`
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)
      const renderMermaid = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
        if (true) initMermaidGestures(item)
        item.__mermaidOriginalSvg = svg
        if (true) attachMermaidViewerButton(item)
      }


      // mermaid v9 and v10 compatibility
      typeof renderFn === 'string' ? renderMermaid(renderFn) : renderFn.then(({ svg }) => renderMermaid(svg))
    })
  }

  const codeToMermaid = () => {
    const codeMermaidEle = document.querySelectorAll('pre > code.mermaid')
    if (codeMermaidEle.length === 0) return

    codeMermaidEle.forEach(ele => {
      const preEle = document.createElement('pre')
      preEle.className = 'mermaid-src'
      preEle.hidden = true
      preEle.textContent = ele.textContent
      const newEle = document.createElement('div')
      newEle.className = 'mermaid-wrap'
      newEle.appendChild(preEle)
      ele.parentNode.replaceWith(newEle)
    })
  }

  const loadMermaid = () => {
    if (true) codeToMermaid()
    const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
    if ($mermaid.length === 0) return

    const runMermaidFn = () => runMermaid($mermaid)
    btf.addGlobalFn('themeChange', runMermaidFn, 'mermaid')
    window.loadMermaid ? runMermaidFn() : btf.getScript('https://cdn.jsdelivr.net/npm/mermaid@11.12.2/dist/mermaid.min.js').then(runMermaidFn)
  }

  btf.addGlobalFn('encrypt', loadMermaid, 'mermaid')
  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>